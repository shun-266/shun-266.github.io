<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>AR Detector</title>
</head>
<body>
    <div>
        <video id="player" playsinline muted autoplay></video>
    </div>
    <div>
        <button id="toggleTracking">ARマーカー検出 & ハンドトラッキング開始</button>
    </div>
    <div>
        <canvas id="canvas" width="640" height="480"></canvas>
    </div>

    <script src="https://docs.opencv.org/4.10.0/opencv.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>

    <script>
        const player = document.getElementById('player');
        const canvas = document.getElementById('canvas');
        const context = canvas.getContext('2d');

        let isCvLoaded = false;
        let isTrackingRunning = false;

        const constraints = { video: { width: 640, height: 480 } };

        const hands = new Hands({
          locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
        });

        hands.setOptions({
          maxNumHands: 2,
          modelComplexity: 1,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        hands.onResults(onResults);

        cv.onRuntimeInitialized = function () {
            isCvLoaded = true;
            console.log("OpenCV.js loaded.");
        };

        navigator.mediaDevices.getUserMedia(constraints)
            .then((stream) => {
                player.srcObject = stream;
            })
            .catch((err) => console.error("Error accessing camera:", err));

        function onResults(results) {
            if (!isTrackingRunning) return;

            context.clearRect(0, 0, canvas.width, canvas.height);
            context.drawImage(player, 0, 0, canvas.width, canvas.height);

            if (results.multiHandLandmarks) {
                for (const [handIndex, landmarks] of results.multiHandLandmarks.entries()) {
                    //console.log(`Hand ${handIndex + 1} Landmarks:`); // 手の番号を表示

                    // 各ランドマークの座標をコンソールに出力
                    landmarks.forEach((landmark, index) => {
                        //console.log(`Landmark ${index}: x: ${landmark.x}, y: ${landmark.y}, z: ${landmark.z}`);
                    });

                    // ランドマークをキャンバスに描画
                    landmarks.forEach((landmark) => {
                        let x = landmark.x * canvas.width;
                        let y = landmark.y * canvas.height;
                        context.beginPath();
                        context.arc(x, y, 5, 0, 2 * Math.PI);
                        context.fillStyle = "red";
                        context.fill();
                });
                }
            }

            if (isTrackingRunning) {
                requestAnimationFrame(() => hands.send({image: player}));
            }
        }

        function detectArucoMarkers(image) {
            let dictionary = new cv.getPredefinedDictionary(cv.DICT_6X6_50);
            let detectorParam = new cv.aruco_DetectorParameters();
            let refineParam = new cv.aruco_RefineParameters(10, 3, true);
            let markerCorners = new cv.MatVector();
            let markerIds = new cv.Mat();

            let ArucoDetector = new cv.aruco_ArucoDetector(dictionary, detectorParam, refineParam);
            ArucoDetector.detectMarkers(image, markerCorners, markerIds);

            return { markerCorners, markerIds };
        }

        function estimatePoseSingleMarkers(corners) {
            let cameraMatrix = cv.matFromArray(3, 3, cv.CV_64F, [
                1018.8031913526505,
                0,
                966.3687199107801,
                0,
                1016.5572863094986,
                509.14712773712756,
                0,
                0,
                1
            ]);
            let distortionCoeffs = cv.matFromArray(1, 5, cv.CV_64F, [
                0.21011422384691603,
                -0.55078108269720494,
                -0.0055280880757881366,
                0.001401219302638096,
                0.46081215822664523
            ]);
            let MarkerSize = 0.05;
            let markerPoints = cv.matFromArray(4, 1, cv.CV_32FC3, [
                -MarkerSize / 2, MarkerSize / 2, 0,
                MarkerSize / 2, MarkerSize / 2, 0,
                MarkerSize / 2, -MarkerSize / 2, 0,
                -MarkerSize / 2, -MarkerSize / 2, 0
            ]);

            let rvecs = [], tvecs = [];

            for (let i = 0; i < corners.size(); i++) {
                let corner = corners.get(i);
                let rvec = new cv.Mat();
                let tvec = new cv.Mat();
                let success = cv.solvePnP(markerPoints, corner, cameraMatrix, distortionCoeffs, rvec, tvec, false, cv.SOLVEPNP_IPPE_SQUARE);

                if (success) {
                    // 回転行列を計算
                    let rotationMatrix = new cv.Mat();
                    cv.Rodrigues(rvec, rotationMatrix);

                    // 回転行列の転置を計算
                    let transposedRotationMatrix = new cv.Mat();
                    cv.transpose(rotationMatrix, transposedRotationMatrix); // transpose() を cv.transpose() に変更

                    // 転置行列のデータをログに出力
                    //console.log(`Marker ${i} Rotation Matrix Transposed:`, transposedRotationMatrix.data64F);

                    // (0, 0, 0) のベクトルを作成
                    let zeroVec = new cv.Mat(3, 1, cv.CV_64F);
                    zeroVec.data64F[0] = 0;
                    zeroVec.data64F[1] = 0;
                    zeroVec.data64F[2] = 0;

                    // tvec から (0, 0, 0) のベクトルを引く
                    let resultVec = new cv.Mat();
                    cv.subtract(zeroVec, tvec, resultVec);

                    // 結果をログに出力
                    //console.log(`Marker ${i} Resulting Vector (from tvec - (0, 0, 0)):`, resultVec.data64F);

                    // resultVec と transposedRotationMatrix の掛け算を行う
                    let multipliedResult = new cv.Mat();
                    cv.gemm(transposedRotationMatrix, resultVec, 1, new cv.Mat(), 0, multipliedResult);

                    // 掛け算結果をログに出力
                    console.log(`Marker ${i} Multiplied Result:`, multipliedResult.data64F);

                    rvecs.push(transposedRotationMatrix);  // 転置された行列を保存
                    tvecs.push(tvec);

                    // メモリ解放
                    rotationMatrix.delete(); // rotationMatrix を先に削除
                    transposedRotationMatrix.delete(); // transposedRotationMatrix を後で削除
                    zeroVec.delete(); // zeroVec を削除
                    resultVec.delete(); // resultVec を削除
                    multipliedResult.delete(); // multipliedResult を削除
                } else {
                    rvec.delete();
                    tvec.delete();
                }
            }

            cameraMatrix.delete();
            distortionCoeffs.delete();
            markerPoints.delete();
            return { rvecs, tvecs };
        }

        function processFrame() {
            if (!isCvLoaded || !isTrackingRunning) return;

            context.drawImage(player, 0, 0, canvas.width, canvas.height);
            let src = cv.imread(canvas);
            
            let { markerCorners, markerIds } = detectArucoMarkers(src);

            if (markerCorners.size() > 0) {
                let { rvecs, tvecs } = estimatePoseSingleMarkers(markerCorners);

                for (let i = 0; i < rvecs.length; i++) {
                    console.log(`Marker ${i}:`);
                    //console.log(`Rotation Vector:`, rvecs[i].data64F);
                    //console.log(`Translation Vector:`, tvecs[i].data64F);

                    tvecs[i].delete();
                }
            }

            markerCorners.delete();
            markerIds.delete();
            src.delete();

            if (isTrackingRunning) {
                requestAnimationFrame(processFrame);
            }
        }

        document.getElementById("toggleTracking").addEventListener("click", function () {
            isTrackingRunning = !isTrackingRunning;
            this.textContent = isTrackingRunning ? "ARマーカー検出 & ハンドトラッキング停止" : "ARマーカー検出 & ハンドトラッキング開始";
            if (isTrackingRunning) {
                processFrame();
                hands.send({ image: player });
            }
        });
    </script>
</body>
</html>