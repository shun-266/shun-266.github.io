<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>AR Detector</title>
</head>
<body>
    <p>ID: <span id="my-id"></span></p>
    <div>
      room name: <input id="room-name" type="text" />
      <button id="join">join</button>
      <button id="leave">leave</button>
    </div>
    <video id="local-video" width="400px" muted playsinline></video>
    <div id="button-area"></div>
    <div id="remote-media-area"></div>
    <div>
        <button id="toggleTracking">ARマーカー検出 & ハンドトラッキング開始</button>
    </div>
    <div>
        <canvas id="canvas" width="640" height="480"></canvas>
    </div>
    <div>
        <video id="player" playsinline muted autoplay style="visibility: hidden;"></video>
    </div>
    <!-- OpenCV -->
    <script src="https://docs.opencv.org/4.10.0/opencv.js"></script>
    <!-- Mediapipe -->
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js"></script>
    <!-- Skyway -->
    <script src="https://cdn.jsdelivr.net/npm/@skyway-sdk/room/dist/skyway_room-latest.js"></script>
    <script>
        //skywayで用いる各種モジュール
        const { nowInSec, SkyWayAuthToken, SkyWayContext, SkyWayRoom, SkyWayStreamFactory, uuidV4 } = skyway_room;

        const buttonArea = document.getElementById("button-area");
        const remoteMediaArea = document.getElementById("remote-media-area");
        const roomNameInput = document.getElementById("room-name");
        const myId = document.getElementById("my-id");
        const joinButton = document.getElementById("join");
        const leaveButton = document.getElementById('leave');

        const token = new SkyWayAuthToken({
        jti: uuidV4(),
        iat: nowInSec(),
        exp: nowInSec() + 60 * 60 * 24,
        version: 3,
        scope: {
            appId: "af868855-f897-4dd2-9098-512871f59642",
            rooms: [
            {
                name: "*",
                methods: ["create", "close", "updateMetadata"],
                member: {
                name: "*",
                methods: ["publish", "subscribe", "updateMetadata"],
                },
            },
            ],
        },
        }).encode("wwAmiNdsFQnwnsBfsuTTYhOEgKEpfeuAemIuM06MPo8=");

        (async () => {
            // 1
            const localVideo = document.getElementById("local-video");

            const { audio, video } = await SkyWayStreamFactory.createMicrophoneAudioAndCameraStream(); // 2

            video.attach(localVideo); // 3
            await localVideo.play(); // 4

            joinButton.onclick = async () => {
                if (roomNameInput.value === "") return;

                const context = await SkyWayContext.Create(token);

                const room = await SkyWayRoom.FindOrCreate(context, {
                type: "p2p",
                name: roomNameInput.value,
                });

                const me = await room.join();

                myId.textContent = me.id;

                await me.publish(audio);
                await me.publish(video);

                const subscribeAndAttach = (publication) => {
                    // 3
                    if (publication.publisher.id === me.id) return;

                    const subscribeButton = document.createElement("button"); // 3-1
                    subscribeButton.id = `subscribe-button-${publication.id}`;
                    subscribeButton.textContent = `${publication.publisher.id}: ${publication.contentType}`;

                    buttonArea.appendChild(subscribeButton);

                    subscribeButton.onclick = async () => {
                        // 3-2
                        const { stream } = await me.subscribe(publication.id); // 3-2-1

                        let newMedia; // 3-2-2
                        switch (stream.track.kind) {
                        case "video":
                            newMedia = document.createElement("video");
                            newMedia.playsInline = true;
                            newMedia.autoplay = true;
                            break;
                        case "audio":
                            newMedia = document.createElement("audio");
                            newMedia.controls = true;
                            newMedia.autoplay = true;
                            break;
                        default:
                            return;
                        }
                        newMedia.id = `media-${publication.id}`;
                        stream.attach(newMedia); // 3-2-3
                        remoteMediaArea.appendChild(newMedia);
                    };
                };

                

                room.publications.forEach(subscribeAndAttach); // 1

                room.onStreamPublished.add((e) => {
                // 2
                subscribeAndAttach(e.publication);
                });

                leaveButton.onclick = async () => {
                await me.leave();
                await room.dispose();

                myId.textContent = "";
                buttonArea.replaceChildren();
                remoteMediaArea.replaceChildren();
                };
            };

        })(); // 1


        const player = document.getElementById('player');
        const canvas = document.getElementById('canvas');
        const context_2d = canvas.getContext('2d');

        let isCvLoaded = false;
        let isTrackingRunning = false;

        const constraints = { video: { width: 640, height: 480 } };

        const hands = new Hands({
          locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`
        });

        hands.setOptions({
          maxNumHands: 2,
          modelComplexity: 1,
          minDetectionConfidence: 0.5,
          minTrackingConfidence: 0.5
        });

        hands.onResults(onResults);

        cv.onRuntimeInitialized = function () {
            isCvLoaded = true;
            console.log("OpenCV.js loaded.");
        };

        navigator.mediaDevices.getUserMedia(constraints)
            .then((stream) => {
                player.srcObject = stream;
            })
            .catch((err) => console.error("Error accessing camera:", err));


        function imageToCameraCoords(pixelX, pixelY, cameraMatrix) {
            let fx = cameraMatrix.data64F[0];  // 焦点距離 (fx)
            let fy = cameraMatrix.data64F[4];  // 焦点距離 (fy)
            let cx = cameraMatrix.data64F[2];  // 主点座標 (cx)
            let cy = cameraMatrix.data64F[5];  // 主点座標 (cy)

            // Z = 1 と仮定してカメラ座標を求める
            let camX = (pixelX - cx) / fx;
            let camY = (pixelY - cy) / fy;
            let camZ = 1.0;  // 仮の値

            return [camX, camY, camZ];
        }

        function cameraToWorldCoords(camX, camY, camZ, rotationMatrix, translationVector) {
            // カメラ座標を行列として作成
            let camPoint = cv.matFromArray(3, 1, cv.CV_64F, [camX, camY, camZ]);

            // 並進ベクトルをカメラ座標から引く
            let relativePoint = new cv.Mat();
            cv.subtract(camPoint, translationVector, relativePoint);

            // 回転行列の逆行列を計算（転置で代用）
            let invRotationMatrix = new cv.Mat();
            cv.transpose(rotationMatrix, invRotationMatrix);

            // カメラ座標をワールド座標に変換
            let worldPoint = new cv.Mat();
            cv.gemm(invRotationMatrix, relativePoint, 1, new cv.Mat(), 0, worldPoint);

            // 結果を取得
            let worldCoords = [worldPoint.data64F[0], worldPoint.data64F[1], worldPoint.data64F[2]];

            // メモリ解放
            camPoint.delete();
            relativePoint.delete();
            invRotationMatrix.delete();
            worldPoint.delete();

            return worldCoords;
        }

        function onResults(results) {
            context_2d.save();
            context_2d.clearRect(0, 0, canvas.width, canvas.height);
            context_2d.drawImage(player, 0, 0, canvas.width, canvas.height);

            if (results.multiHandLandmarks) {
                for (const landmarks of results.multiHandLandmarks) {
                    window.drawConnectors(context_2d, landmarks, HAND_CONNECTIONS, {
                        color: '#00FF00', lineWidth: 5
                    });
                    window.drawLandmarks(context_2d, landmarks, {
                        color: '#FF0000', lineWidth: 2
                    });
                }
            }
            context_2d.restore();

            if (isTrackingRunning) {
                requestAnimationFrame(() => hands.send({ image: player }));
            }
        }


        function detectArucoMarkers(image) {
            let dictionary = new cv.getPredefinedDictionary(cv.DICT_6X6_50);
            let detectorParam = new cv.aruco_DetectorParameters();
            let refineParam = new cv.aruco_RefineParameters(10, 3, true);
            let markerCorners = new cv.MatVector();
            let markerIds = new cv.Mat();

            let ArucoDetector = new cv.aruco_ArucoDetector(dictionary, detectorParam, refineParam);
            ArucoDetector.detectMarkers(image, markerCorners, markerIds);

            return { markerCorners, markerIds };
        }

        function estimatePoseSingleMarkers(corners) {
            let cameraMatrix = cv.matFromArray(3, 3, cv.CV_64F, [
                1018.8031913526505, 0, 966.3687199107801,
                0, 1016.5572863094986, 509.14712773712756,
                0, 0, 1
            ]);
            let distortionCoeffs = cv.matFromArray(1, 5, cv.CV_64F, [
                0.21011422384691603, -0.55078108269720494, 
                -0.0055280880757881366, 0.001401219302638096, 
                0.46081215822664523
            ]);
            let MarkerSize = 0.05;
            let markerPoints = cv.matFromArray(4, 1, cv.CV_32FC3, [
                -MarkerSize / 2, MarkerSize / 2, 0,
                MarkerSize / 2, MarkerSize / 2, 0,
                MarkerSize / 2, -MarkerSize / 2, 0,
                -MarkerSize / 2, -MarkerSize / 2, 0
            ]);

            let rvecs = [], tvecs = [], camera_positions = [];

            for (let i = 0; i < corners.size(); i++) {
                let corner = corners.get(i);
                let rvec = new cv.Mat();
                let tvec = new cv.Mat();
                let success = cv.solvePnP(markerPoints, corner, cameraMatrix, distortionCoeffs, rvec, tvec, false, cv.SOLVEPNP_IPPE_SQUARE);

                if (success) {
                    let camera_position = computeCamerpos(rvec, tvec);
                    console.log(`Marker ${i} camera_position:`, camera_position.data64F);

                    rvecs.push(rvec);
                    tvecs.push(tvec);
                    camera_positions.push(camera_position);  // camera_position も保存
                } else {
                    rvec.delete();
                    tvec.delete();
                }
            }

            // メモリ解放
            cameraMatrix.delete();
            distortionCoeffs.delete();
            markerPoints.delete();

            return { rvecs, tvecs, camera_positions };  // camera_positions も返す
        }

        function computeCamerpos(rvec, tvec) {
            let rotationMatrix = new cv.Mat();
            cv.Rodrigues(rvec, rotationMatrix);

            let transposedRotationMatrix = new cv.Mat();
            cv.transpose(rotationMatrix, transposedRotationMatrix);

            let zeroVec = cv.Mat.zeros(3, 1, cv.CV_64F);
            let resultVec = new cv.Mat();
            cv.subtract(zeroVec, tvec, resultVec);

            let camera_position = new cv.Mat();
            cv.gemm(transposedRotationMatrix, resultVec, 1, new cv.Mat(), 0, camera_position);

            // メモリ解放（不要なMatを削除）
            rotationMatrix.delete();
            transposedRotationMatrix.delete();
            zeroVec.delete();
            resultVec.delete();

            return camera_position;  // camera_position は呼び出し側で delete する
        }

        function processFrame() {
            if (!isCvLoaded || !isTrackingRunning) return;

            context_2d.drawImage(player, 0, 0, canvas.width, canvas.height);
            let src = cv.imread(canvas);
            
            let { markerCorners, markerIds } = detectArucoMarkers(src);

            if (markerCorners.size() > 0) {
                let { rvecs, tvecs, camera_positions } = estimatePoseSingleMarkers(markerCorners);

                for (let i = 0; i < camera_positions.length; i++) {
                    console.log(`Marker ${i} Camera Position:`, camera_positions[i].data64F);
                    camera_positions[i].delete();  // ここで解放！
                }
            }

            markerCorners.delete();
            markerIds.delete();
            src.delete();

            if (isTrackingRunning) {
                requestAnimationFrame(processFrame);
            }
        }

        document.getElementById("toggleTracking").addEventListener("click", function () {
            isTrackingRunning = !isTrackingRunning;
            this.textContent = isTrackingRunning ? "ARマーカー検出 & ハンドトラッキング停止" : "ARマーカー検出 & ハンドトラッキング開始";
            if (isTrackingRunning) {
                processFrame();
                hands.send({ image: player });
            }
        });
    </script>
</body>
</html>